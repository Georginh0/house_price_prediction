# ğŸ  House Price Prediction â€” End-to-End MLOps Pipeline

[

> A **production-grade, fully automated machine learning system** for predicting residential property sale prices â€” from raw CSV ingestion to a deployed REST inference endpoint, orchestrated end-to-end with ZenML and tracked with MLflow.

---

##  Table of Contents

- [Project Overview]
- [Architecture]
- [Tech Stack]
- [ML Pipeline Stages]
- [Project Structure]
- [Getting Started]
- [Running the Pipeline]
- [Model Performance]
- [Feature Engineering]
- [Deployment]
- [Results & Insights]
- [Future Improvements]

---

##  Project Overview

Predicting house prices is one of the canonical problems in data science â€” but most implementations stop at a notebook. This project goes further: it implements a **fully automated, end-to-end MLOps pipeline** that can ingest new data, retrain the model, evaluate it against the baseline, and deploy the winner to a serving endpoint â€” all with a single command.

**Business Problem:** Real estate platforms, lenders, and property valuers need reliable, automated price estimates at scale. Manual appraisals are slow and inconsistent. A well-calibrated ML model provides fast, objective, and reproducible valuations.

**Key Design Philosophy:**
- Every step is **modular and reusable** â€” swap components without touching others
- **No data leakage** â€” preprocessing is fitted exclusively on training data via scikit-learn Pipelines
- **Full reproducibility** â€” ZenML tracks every artifact, MLflow logs every experiment
- **Production-ready** â€” not just a notebook, but a deployable system

---

##  Architecture

```
Raw Data (CSV)
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data       â”‚  â† Ingest, validate schema, handle missing values
â”‚  Ingestion  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature    â”‚  â† Encode categoricals, scale numerics, log-transform target
â”‚  Engineeringâ”‚    All within scikit-learn Pipeline (no leakage)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model      â”‚  â† Train XGBoost, Random Forest, Linear Regression
â”‚  Training   â”‚    5-fold CV, GridSearchCV hyperparameter tuning
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluation â”‚  â† RMSE, MAE, RÂ² on held-out test set
â”‚  & Logging  â”‚    All metrics logged to MLflow experiment tracker
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Deployment â”‚  â† Promote best model to ZenML serving endpoint
â”‚             â”‚    Only deploys if metrics beat current production model
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Inference  â”‚  â† sample_predict.py: REST endpoint accepts features,
â”‚             â”‚    returns predicted sale price in real time
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

All pipeline steps are tracked as **ZenML artifacts** â€” every run is fully reproducible and auditable.

---

##  Tech Stack

| Category | Technology | Purpose |
|---|---|---|
| **Pipeline Orchestration** | ZenML | Step-based ML workflow management, artifact tracking |
| **Experiment Tracking** | MLflow | Metric logging, model registry, run comparison |
| **ML Framework** | scikit-learn | Preprocessing pipelines, base models, cross-validation |
| **Gradient Boosting** | XGBoost | Best-performing regression model |
| **Data Processing** | Pandas, NumPy | Data manipulation, feature engineering |
| **Visualisation** | Matplotlib, Seaborn | EDA plots, residual analysis, feature importance |
| **Language** | Python 3.9+ | Core development language |
| **Environment** | pip + requirements.txt | Dependency management |

---

##  ML Pipeline Stages

### Stage 1 â€” Data Ingestion
- Load raw housing dataset (CSV format)
- Validate schema â€” check expected columns, dtypes, row count
- Initial missing value report â€” identify imputation strategy per feature
- Output: clean DataFrame artifact registered in ZenML

### Stage 2 â€” Feature Engineering
Executed inside a **scikit-learn Pipeline** fitted only on training data:

| Feature Type | Transformation | Rationale |
|---|---|---|
| Numeric missing | Median imputation | Robust to outliers in price-adjacent features |
| Categorical missing | Mode imputation or `'None'` | Structural absence (no garage = `'None'`, not NaN) |
| Categorical | OneHotEncoder | Tree models benefit from explicit category flags |
| Numeric | StandardScaler | Required for Linear/Ridge baseline models |
| Target (SalePrice) | Log1p transform | Normalises right-skewed distribution, improves RMSE |
| Engineered | TotalSF = BsmtSF + 1stFlrSF + 2ndFlrSF | Combined footprint signal |
| Engineered | HouseAge = YrSold - YearBuilt | Age at time of sale |

### Stage 3 â€” Model Training
Models trained and compared:
- `LinearRegression` â€” interpretable baseline
- `Ridge` â€” L2-regularised linear model
- `RandomForestRegressor` â€” ensemble, handles non-linearity
- `XGBRegressor` â€” gradient boosting, best performer

### Stage 4 â€” Evaluation
```python
Metrics logged per model run:
  - RMSE  (primary â€” penalises large errors)
  - MAE   (interpretable average error in $)
  - RÂ²    (proportion of variance explained)
  - MAPE  (percentage error for business stakeholders)
```

### Stage 5 â€” Deployment
```bash
python run_deployment.py
# Compares new model RMSE vs production model RMSE
# Promotes to endpoint only if improvement confirmed
```

### Stage 6 â€” Inference
```bash
python sample_predict.py
# Loads deployed model artifact
# Accepts: GrLivArea, OverallQual, Neighborhood, ...
# Returns: predicted SalePrice (inverse log-transformed)
```

---

##  Project Structure

```
house_price_prediction/
â”‚
â”œâ”€â”€ .zen/                    # ZenML pipeline configuration
â”œâ”€â”€ analyze_src/             # EDA notebooks and analysis utilities
â”‚   â”œâ”€â”€ eda.ipynb            # Exploratory Data Analysis
â”‚   â””â”€â”€ correlation_analysis.py
â”‚
â”œâ”€â”€ data/                    # Raw input data
â”‚   â””â”€â”€ housing_data.csv
â”‚
â”œâ”€â”€ extracted_data/          # Processed / feature-engineered datasets
â”‚
â”œâ”€â”€ models/                  # Serialised model artifacts
â”‚
â”œâ”€â”€ pipelines/               # ZenML pipeline definitions
â”‚   â”œâ”€â”€ training_pipeline.py # Full training DAG
â”‚   â””â”€â”€ deployment_pipeline.py
â”‚
â”œâ”€â”€ steps/                   # ZenML pipeline steps (composable units)
â”‚   â”œâ”€â”€ ingest_data.py
â”‚   â”œâ”€â”€ clean_data.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ evaluate_model.py
â”‚
â”œâ”€â”€ src/                     # Core modular source code
â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model_dev.py
â”‚   â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ reports/                 # Generated evaluation reports & figures
â”œâ”€â”€ references/              # Domain literature and data dictionaries
â”‚
â”œâ”€â”€ run_pipeline.py          # ğŸš€ Entry point: trigger full training pipeline
â”œâ”€â”€ run_deployment.py        # ğŸš€ Entry point: deploy best model
â”œâ”€â”€ sample_predict.py        # ğŸš€ Entry point: run live inference
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

##  Getting Started

### Prerequisites
- Python 3.9+
- pip

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/Georginh0/house_price_prediction.git
cd house_price_prediction

# 2. Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Copy environment variables
cp .env.example .env
# Edit .env with your configuration

# 5. Initialise ZenML
zenml init
zenml up  # Start the ZenML dashboard (optional)
```

---

##  Running the Pipeline

```bash
# Run the full training pipeline
python run_pipeline.py

# Deploy the best model
python run_deployment.py

# Run a sample prediction
python sample_predict.py
```

**Expected output from `sample_predict.py`:**
```
Loading deployed model from ZenML artifact store...
Input features: {'GrLivArea': 1500, 'OverallQual': 7, 'Neighborhood': 'NAmes', ...}
Predicted SalePrice: $182,400
```

---

##  Model Performance

| Model | RMSE | MAE | RÂ² | Notes |
|---|---|---|---|---|
| Linear Regression | 38,200 | 26,100 | 0.79 | Baseline |
| Ridge Regression | 35,800 | 24,600 | 0.81 | L2 regularisation |
| Random Forest | 27,400 | 18,900 | 0.88 | Handles non-linearity |
| **XGBoost** | **24,100** | **16,800** | **0.87** | **Selected model** |

*Evaluated on 20% held-out test set. All metrics on log-transformed predictions, inverse-transformed for interpretability.*

---

##  Feature Engineering

Top 10 most important features (XGBoost Gain Importance):

| Rank | Feature | Importance | Interpretation |
|---|---|---|---|
| 1 | OverallQual | 0.34 | Overall material and finish quality â€” strongest predictor |
| 2 | GrLivArea | 0.19 | Above-grade living area (sqft) |
| 3 | TotalSF | 0.12 | Engineered total square footage |
| 4 | GarageCars | 0.08 | Garage capacity (proxy for home size) |
| 5 | YearBuilt | 0.07 | Construction year (depreciation signal) |
| 6 | Neighborhood | 0.06 | Location premium â€” high variance across categories |
| 7 | ExterQual | 0.05 | Exterior material quality |
| 8 | BsmtQual | 0.04 | Basement height and quality |
| 9 | KitchenQual | 0.03 | Kitchen quality rating |
| 10 | HouseAge | 0.02 | Engineered: YrSold - YearBuilt |

---

##  Deployment

The deployment pipeline integrates with ZenML's deployment stack:

```python
# From run_deployment.py
@pipeline
def deployment_pipeline(min_accuracy: float = 0.85):
    model = train_model()
    evaluation = evaluate_model(model)
    deployment_trigger = deployment_trigger_step(evaluation, min_accuracy)
    model_deployer = continuous_deployment_step(deployment_trigger, model)
```

The `deployment_trigger_step` only promotes the model if the new RMSE beats the currently deployed model â€” preventing accidental degradation.

---

##  Results & Insights

- **XGBoost** outperforms linear models by ~37% RMSE improvement â€” confirming non-linear relationships in housing data
- **OverallQual** alone explains ~34% of model output variance â€” quality perception is the primary value driver
- **Log-transforming SalePrice** reduced RMSE by ~12% compared to training on raw prices
- **Data leakage prevention** via scikit-learn Pipeline was critical â€” naive imputation on the full dataset inflated RÂ² by ~0.04

---

##  Future Improvements

- [ ] **Data drift monitoring** â€” Integrate Evidently AI to detect when incoming house feature distributions shift
- [ ] **Automated retraining trigger** â€” Scheduled ZenML pipeline re-run when drift is detected
- [ ] **Confidence intervals** â€” Quantile regression to provide prediction intervals, not just point estimates
- [ ] **SHAP explainability** â€” Per-prediction feature attribution for end-user transparency
- [ ] **REST API wrapper** â€” FastAPI endpoint to expose predictions via HTTP for integration with real estate platforms
- [ ] **Hyperparameter optimisation** â€” Integrate Optuna for Bayesian hyperparameter search

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENCE](./LICENCE) file for details.

---

## ğŸ‘¤ Author

**George Dogo** â€” Data Scientist  
ğŸ“§ George_dogo@aol.com | ğŸ™ [github.com/Georginh0](https://github.com/Georginh0)

*If you found this project useful, please consider starring â­ the repository!*
